
10.07
问题：直接使用 music_lstm_gan 训练一定 epoch 后生成的音乐无多样性，往往只是某一个音符的重复
原因分析：G 能力不足（训练方式导致），此时假设 G 的单步输出为该步的对数几率，但没有任何支持该假设的地方
解决方案：迁移 music_vae 的训练，在它的训练中 decoder 的重构损失对上述假设有支持
效果：待训练

10.08
修改：修改至可以在 GPU 上训练
原因：不能在 GPU 上训练的原因
    虚拟环境里应该使用 conda 安装 tensorflow-gpu ，之前使用 pip 安装，但是 pip 安装的版本没有针对新的 cuda10 版本编译
效果：训练一定 epoch 后，仍会出现未迁移时的情况。但是，通过比较不同 epoch 生成的音乐发现 “污染” 从后开始

10.09
添加：添加 3D-CNN 做 D
原因：通过上面的观察，认为只用 LSTM 的最后一时间步的 output 判断有问题。于是，再次尝试 3D-CNN 做 D
效果：仍会出现 D 的 loss 上升至某值后不下降，但生成的音乐比之前的更多样性，可碎片化更严重

10.10
疑问：之前的 D update 有问题??

10.11
修改：修改 D 的权重更新 BUG
问题：
    1）clip 操作应该依赖于权重更新（即 clip 应该在权重更新完成后执行），但之前的代码没有保障 == 该原因的可能极大
    2）优化器的 minimize 与分拆的操作 `compute_gradients` `apply_gradients` 的关系 ==> 没问题

10.16
修改：添加 2DCNN D

10.17
修改：为 G D 添加预训练逻辑

10.19
修改：G 的预训练逻辑，预训练时携带模拟的隐变量 z(零向量)

10.20
修改：代码整理
发现问题：MusicVAE 中使用“分层”的 LSTM 是因为单 LSTM 不足以生成长序列。而实验中一直在使用单层的 LSTM

10.22
实验：迁移 MusicVAE 的解码器（生成器）进行预训练 500 步后发现能达到 0.6798373
     而直接使用 MusicVAE 的解码器（生成器）进行预训练 500 步后发现只能达到 0.5961291
添加：实现 SeqGAN

10.23
修改：为预训练的梯度下降指定可训练的变量
问题：生成器的每一时间步的下一次输出使用 argmax or 使用 one-hot 采样
     现在使用的是 one-hot 采样，以使得产生的数据更多样，但并没有显现

10.25
修改：生成音乐的长度，之前直接默认为最大序列长度